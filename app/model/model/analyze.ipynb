{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "gOu8MC5Arv2m"
      },
      "outputs": [],
      "source": [
        "!pip install catboost lightgbm gensim nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "LqGqzFN2rnT1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import SnowballStemmer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import os\n",
        "import pickle\n",
        "from sklearn.svm import SVC\n",
        "import lightgbm as lgb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0VM5De2OZ7xh"
      },
      "outputs": [],
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNq233sY8QeB"
      },
      "source": [
        "#Предобработка данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "mvDVFVg3r5GG"
      },
      "outputs": [],
      "source": [
        "train_data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Samokat/amazon/train_40k.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0_lcUVZCr7Cc"
      },
      "outputs": [],
      "source": [
        "train_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "id": "eup-4tV0Bg9l",
        "outputId": "490df0d3-85fe-458d-dc2d-783869984d25"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Cat3</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>unknown</th>\n",
              "      <td>2262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>shaving hair removal</th>\n",
              "      <td>1565</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vitamins supplements</th>\n",
              "      <td>1315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>board games</th>\n",
              "      <td>924</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>styling tools</th>\n",
              "      <td>850</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pork</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>games</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>game collections</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fruits</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sports drinks</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>464 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "Cat3\n",
              "unknown                 2262\n",
              "shaving hair removal    1565\n",
              "vitamins supplements    1315\n",
              "board games              924\n",
              "styling tools            850\n",
              "                        ... \n",
              "pork                       1\n",
              "games                      1\n",
              "game collections           1\n",
              "fruits                     1\n",
              "sports drinks              1\n",
              "Name: count, Length: 464, dtype: int64"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data.value_counts('Cat3')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0jIEh0SXB8tH"
      },
      "outputs": [],
      "source": [
        "threshold = 20\n",
        "class_counts = train_data['Cat3'].value_counts()\n",
        "\n",
        "# Замена редких классов на 'Other'\n",
        "train_data['Cat3'] = train_data['Cat3'].apply(lambda x: x if class_counts[x] > threshold else 'Other')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "id": "MWreXV70CDip",
        "outputId": "1fd5bf37-e2b7-4a1c-bef5-6d98b92f4bfc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Cat3</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>unknown</th>\n",
              "      <td>2262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Other</th>\n",
              "      <td>1566</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>shaving hair removal</th>\n",
              "      <td>1565</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vitamins supplements</th>\n",
              "      <td>1315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>board games</th>\n",
              "      <td>924</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>water treatments</th>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>aquarium d cor</th>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>teddy bears</th>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>changing table pads covers</th>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>party mix</th>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>239 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "Cat3\n",
              "unknown                       2262\n",
              "Other                         1566\n",
              "shaving hair removal          1565\n",
              "vitamins supplements          1315\n",
              "board games                    924\n",
              "                              ... \n",
              "water treatments                22\n",
              "aquarium d cor                  22\n",
              "teddy bears                     21\n",
              "changing table pads covers      21\n",
              "party mix                       21\n",
              "Name: count, Length: 239, dtype: int64"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data.value_counts('Cat3')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JZpDy2KsaaOA"
      },
      "outputs": [],
      "source": [
        "train_data['length'] = train_data['Text'].apply(len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5V7gju6YbA5E"
      },
      "outputs": [],
      "source": [
        "train_data = train_data[train_data['Text'].apply(lambda x: len(x) >= 5)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "sUJ0EdZUbH9c",
        "outputId": "65f983c4-1443-444b-fcb1-e9c5fee22c30"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[<Axes: title={'center': 'length'}>]], dtype=object)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "train_data.hist(column='length', bins=500, figsize=(12,4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAodYvl_8dcw"
      },
      "source": [
        "#Реализация класса иерархического классификатора"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xP1LjDq8qBt"
      },
      "source": [
        "## Структура Local Classifier per Parent Node (LCPN) - каждый родительский узел получает один многоклассовый классификатор."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kfh6OMF1x8__"
      },
      "outputs": [],
      "source": [
        "class LCPN_HierarchicalClassifier:\n",
        "\n",
        "    def __init__(self, base_model):\n",
        "        self.base_model = base_model\n",
        "        self.models = {}\n",
        "        self.label_encoders = {}\n",
        "        self.vectorizer = TfidfVectorizer()\n",
        "\n",
        "\n",
        "    def preprocess_text(self, text):\n",
        "        \"\"\"\n",
        "        Функция предобработки текста для корректной векторизации и работы модели\n",
        "        \"\"\"\n",
        "        tokens = word_tokenize(text)\n",
        "        tokens = [word.lower() for word in tokens if word.isalpha()]\n",
        "        stop_words = set(stopwords.words('english'))\n",
        "        filtered_tokens = [word for word in tokens if word not in stop_words]\n",
        "        stemmer = SnowballStemmer('english')\n",
        "        stemmed_tokens = [stemmer.stem(word) for word in filtered_tokens]\n",
        "        return ' '.join(stemmed_tokens)\n",
        "\n",
        "\n",
        "    def fit(self, train_data, catboost=False):\n",
        "        \"\"\"\n",
        "        Функция тренировки модели.\n",
        "        Входные данные предобрабатываются и векторизируются методом TfIdf для упрощения.\n",
        "        На каждый уровень реализуется отдельный LabelEncoder.\n",
        "        Если уровень больше первого, каждый классификатор тренируется на тех данных,\n",
        "        которые соответствуют родительскому узлу.\n",
        "        В словарь models сохраняем модели по определенному уровню и родительскому узлу.\n",
        "        Также сохраняем label_encoder'ы для будущих предсказаний и определения точности моделей.\n",
        "        \"\"\"\n",
        "        train_data['Processed_Text'] = train_data['Text'].apply(self.preprocess_text)\n",
        "        X = self.vectorizer.fit_transform(train_data['Processed_Text']).astype(np.float32)\n",
        "\n",
        "        for level in range(1, 4):\n",
        "            cat_column = f'Cat{level}'\n",
        "            label_encoder = LabelEncoder()\n",
        "            y = label_encoder.fit_transform(train_data[cat_column])\n",
        "\n",
        "            self.label_encoders[level] = label_encoder\n",
        "\n",
        "            if level == 1:\n",
        "                self.models['start'] = self.base_model.fit(X, y) # Если уровень первый, то обучаем на всем дататсете с колонки Cat1\n",
        "            else:\n",
        "                self.models[level] = {}\n",
        "                for label in train_data[f'Cat{level-1}'].unique():\n",
        "                    indices = train_data[f'Cat{level-1}'] == label\n",
        "                    X_label = X[indices]\n",
        "                    y_label = y[indices]\n",
        "\n",
        "                    if len(set(y_label)) == 1:\n",
        "                        continue\n",
        "\n",
        "                    X_train, X_test, y_train, y_test = train_test_split(X_label, y_label, test_size=0.25)\n",
        "\n",
        "                    if catboost:\n",
        "                        self.models[level][label] = self.base_model.fit(X_train, y_train)\n",
        "                    else:\n",
        "                        self.models[level][label] = self.base_model.set_params(class_weight='balanced').fit(X_train, y_train)\n",
        "\n",
        "                    y_pred = self.models[level][label].predict(X_test)\n",
        "\n",
        "                    print(f'--- Level {level}, Parent Label: {label} ---')\n",
        "                    print(f'Accuracy: {accuracy_score(y_test, y_pred)}')\n",
        "                    print(f'F1 Score: {f1_score(y_test, y_pred, average=\"macro\")}')\n",
        "                    print(f\"Recall score: {recall_score(y_test, y_pred, average='macro')}\")\n",
        "                    print(f\"Precision score: {precision_score(y_test, y_pred, average='macro')}\")\n",
        "\n",
        "        return self\n",
        "\n",
        "\n",
        "    def transform_with_unknown(self, label_encoder, labels):\n",
        "        \"\"\"\n",
        "        Функция работы с отстутствующими метками.\n",
        "        При получении новых данных мы можем получить неизвестные метки для label encoder,\n",
        "        что вызывает ошибку.\n",
        "        Чтобы решить эту проблему функция преобразует метки, заменяя новые метки на 'Unknown'.\n",
        "        \"\"\"\n",
        "\n",
        "        known_labels = set(label_encoder.classes_)\n",
        "        transformed_labels = []\n",
        "\n",
        "        for label in labels:\n",
        "            if label in known_labels:\n",
        "                transformed_labels.append(label_encoder.transform([label])[0])\n",
        "            else:\n",
        "                transformed_labels.append(label_encoder.transform([\"Unknown\"])[0])\n",
        "\n",
        "        return np.array(transformed_labels)\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Функция предсказания.\n",
        "        Полученные данные векторизуются и подаются поочередно на каждый уровень\n",
        "        в зависимости от предсказанного класса. Каждое предсказанный класс сохраняется\n",
        "        в список y_pred_hierarchical.\n",
        "        Возвращается последний предсказанный класс и список всех классов.\n",
        "        \"\"\"\n",
        "\n",
        "        X = X.apply(self.preprocess_text)\n",
        "        X_transformed = self.vectorizer.transform(X)\n",
        "\n",
        "        y_pred_level_1 = self.models['start'].predict(X_transformed)\n",
        "        y_pred_hierarchical = [y_pred_level_1]\n",
        "\n",
        "        for level in range(2, 4):\n",
        "            y_pred_level = np.zeros_like(y_pred_level_1)\n",
        "            for i, label in enumerate(y_pred_hierarchical[-1]):\n",
        "                if label in self.models[level]:\n",
        "                    y_pred_level[i] = self.models[level][label].predict([X_transformed[i]])[0]\n",
        "                else:\n",
        "                    y_pred_level[i] = self.label_encoders[level].transform([\"Unknown\"])[0]\n",
        "            y_pred_hierarchical.append(y_pred_level)\n",
        "\n",
        "        return y_pred_hierarchical[-1], y_pred_hierarchical\n",
        "\n",
        "    def evaluate(self, test_data):\n",
        "        '''\n",
        "        Функция оценивания качества на тестовых данных.\n",
        "        Возвращаеn cловарь metrics, содержащий метрики качества\n",
        "        (accuracy, f1, recall, precision) для каждого уровня иерархии (Cat1, Cat2, Cat3).\n",
        "        '''\n",
        "        test_data['Processed_Text'] = test_data['Text'].apply(self.preprocess_text)\n",
        "        X_test = self.vectorizer.transform(test_data['Processed_Text']).astype(np.float32)\n",
        "\n",
        "        metrics = {f'Cat{level}': {'accuracy': [], 'f1': [], 'recall': [], 'precision': []} for level in range(1, 4)}\n",
        "\n",
        "        y_test_level_1 = self.transform_with_unknown(self.label_encoders[1], test_data['Cat1'])\n",
        "        y_pred_level_1 = self.models['start'].predict(X_test)\n",
        "\n",
        "        metrics['Cat1']['accuracy'].append(accuracy_score(y_test_level_1, y_pred_level_1))\n",
        "        metrics['Cat1']['f1'].append(f1_score(y_test_level_1, y_pred_level_1, average='macro'))\n",
        "        metrics['Cat1']['recall'].append(recall_score(y_test_level_1, y_pred_level_1, average='macro'))\n",
        "        metrics['Cat1']['precision'].append(precision_score(y_test_level_1, y_pred_level_1, average='macro'))\n",
        "\n",
        "        y_pred_hierarchical = [y_pred_level_1]\n",
        "\n",
        "        for level in range(2, 4):\n",
        "            y_test_level = self.transform_with_unknown(self.label_encoders[level], test_data[f'Cat{level}'])\n",
        "            y_pred_level = np.zeros_like(y_test_level)\n",
        "\n",
        "            for i, label in enumerate(y_pred_hierarchical[-1]):\n",
        "                if label in self.models[level]:\n",
        "                    y_pred_level[i] = self.models[level][label].predict([X_test[i]])[0]\n",
        "                else:\n",
        "                    y_pred_level[i] = self.label_encoders[level].transform([\"Unknown\"])[0]\n",
        "\n",
        "            y_pred_hierarchical.append(y_pred_level)\n",
        "\n",
        "            metrics[f'Cat{level}']['accuracy'].append(accuracy_score(y_test_level, y_pred_level))\n",
        "            metrics[f'Cat{level}']['f1'].append(f1_score(y_test_level, y_pred_level, average='macro'))\n",
        "            metrics[f'Cat{level}']['recall'].append(recall_score(y_test_level, y_pred_level, average='macro'))\n",
        "            metrics[f'Cat{level}']['precision'].append(precision_score(y_test_level, y_pred_level, average='macro'))\n",
        "\n",
        "        return metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lu5WLl81VuSW"
      },
      "outputs": [],
      "source": [
        "base_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "hc = LCPN_HierarchicalClassifier(base_model)\n",
        "hc.fit(train_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7aGvwIXAn3v0"
      },
      "source": [
        "**Результат**:\n",
        "\n",
        "метрики верхних уровней на тренировочных данных:\n",
        "- accuracy = 0.6\n",
        "- F1 = 0.4\n",
        "\n",
        "Метрики нижних классов показывают очень низкое качество даже на тренировочной выборке. Возможной причиной является недостаток количества тренировочных данных для определенных категорий."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqIR_wG1ojMS"
      },
      "source": [
        "## Структура Local Classifier per Node (LCN) - обучение одного многоклассового классификатора для каждого уровня."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iVKhtoFoRPn6"
      },
      "outputs": [],
      "source": [
        "from gensim.models import Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mj85qQ6niVLE"
      },
      "outputs": [],
      "source": [
        "class LCN_HierarchicalClassifier:\n",
        "\n",
        "    def __init__(self, base_model):\n",
        "        self.base_model = base_model\n",
        "        self.models = {}\n",
        "        self.label_encoders = {}\n",
        "\n",
        "\n",
        "    def preprocess_text(self, text):\n",
        "        tokens = word_tokenize(text)\n",
        "        tokens = [word.lower() for word in tokens if word.isalpha()]\n",
        "        stop_words = set(stopwords.words('english'))\n",
        "        filtered_tokens = [word for word in tokens if word not in stop_words]\n",
        "        stemmer =  SnowballStemmer('english')\n",
        "        stemmed_tokens = [stemmer.stem(word) for word in filtered_tokens]\n",
        "        return ' '.join(stemmed_tokens)\n",
        "\n",
        "    def fit_word2vec(self, text):\n",
        "        \"\"\"\n",
        "        Функция тренировки word2vec.\n",
        "        Для нахождения более сложных зависимостей и пополнения признаков\n",
        "        обучаем word2vec.\n",
        "        \"\"\"\n",
        "        self.word2vec_model = Word2Vec(text)\n",
        "        self.word2vec_model.train(text, total_examples=len(text), epochs=5)\n",
        "        return self.word2vec_model\n",
        "\n",
        "    def text_to_vector(self, text):\n",
        "        \"\"\"\n",
        "        Функция преобразования текста в вектора.\n",
        "        \"\"\"\n",
        "        words = self.preprocess_text(text)\n",
        "        words_in_vocab = [word for word in words if word in self.word2vec_model.wv]\n",
        "        if len(words_in_vocab) == 0:\n",
        "            return np.zeros(100)\n",
        "        return np.mean([self.word2vec_model.wv[word] for word in words_in_vocab], axis=0)\n",
        "\n",
        "    def fit(self, train_data, save_model_dir=None):\n",
        "        \"\"\"\n",
        "        Функция тренировки.\n",
        "        Ход работы аналогичен классу LCPN, но здесь тренировка идет только по уровням,\n",
        "        поэтому кол-во классификаторов равно кол-ву уровней.\n",
        "        Также добавлена возможность сохранения весов моделелей.\n",
        "        \"\"\"\n",
        "        train_data['Processed_Text'] = train_data['Text'].apply(self.preprocess_text)\n",
        "        text = train_data['Processed_Text'].tolist()\n",
        "\n",
        "        # Преобразование текста в векторы\n",
        "        X = np.array([self.text_to_vector(text) for text in train_data['Processed_Text']])\n",
        "\n",
        "        for level in range(1, 4):\n",
        "            cat_column = f'Cat{level}'\n",
        "            label_encoder = LabelEncoder()\n",
        "            y = label_encoder.fit_transform(train_data[cat_column])\n",
        "\n",
        "            if \"Unknown\" not in label_encoder.classes_:\n",
        "                label_encoder.classes_ = np.append(label_encoder.classes_, \"Unknown\")\n",
        "\n",
        "            self.label_encoders[level] = label_encoder\n",
        "\n",
        "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
        "            self.models[level] = self.base_model.fit(X_train, y_train)\n",
        "\n",
        "            if save_model_dir:\n",
        "                model_path = os.path.join(save_model_dir, f'/content/drive/MyDrive/Colab Notebooks/Samokat/weights/model_level_{level}.pkl')\n",
        "                encoder_path = os.path.join(save_model_dir, f'/content/drive/MyDrive/Colab Notebooks/Samokat/weights/encoder_level_{level}.pkl')\n",
        "                with open(model_path, 'wb') as model_file:\n",
        "                    pickle.dump(self.models[level], model_file)\n",
        "                with open(encoder_path, 'wb') as encoder_file:\n",
        "                    pickle.dump(self.label_encoders[level], encoder_file)\n",
        "\n",
        "            y_pred = self.models[level].predict(X_test)\n",
        "\n",
        "            print(f'--- Level {level} ---')\n",
        "            print(f'Accuracy: {accuracy_score(y_test, y_pred)}')\n",
        "            print(f'F1 Score: {f1_score(y_test, y_pred, average=\"macro\")}')\n",
        "            print(f\"Recall score: {recall_score(y_test, y_pred, average='macro')}\")\n",
        "            print(f\"Precision score: {precision_score(y_test, y_pred, average='macro')}\")\n",
        "\n",
        "        return self\n",
        "\n",
        "    def transform_with_unknown(self, label_encoder, labels):\n",
        "        known_labels = set(label_encoder.classes_)\n",
        "        transformed_labels = []\n",
        "\n",
        "        for label in labels:\n",
        "            if label in known_labels:\n",
        "                transformed_labels.append(label_encoder.transform([label])[0])\n",
        "            else:\n",
        "                transformed_labels.append(label_encoder.transform([\"Unknown\"])[0])\n",
        "\n",
        "        return np.array(transformed_labels)\n",
        "\n",
        "    def predict(self, X, model_dir=None):\n",
        "        if model_dir:   # Импорт обученной модели\n",
        "            for level in range(1, 4):\n",
        "                model_path = os.path.join(model_dir, f'model_level_{level}.pkl')\n",
        "                encoder_path = os.path.join(model_dir, f'encoder_level_{level}.pkl')\n",
        "                with open(model_path, 'rb') as model_file:\n",
        "                    self.models[level] = pickle.load(model_file)\n",
        "                with open(encoder_path, 'rb') as encoder_file:\n",
        "                    self.label_encoders[level] = pickle.load(encoder_file)\n",
        "\n",
        "        X = X.apply(self.preprocess_text)\n",
        "        X_transformed = self.vectorizer.transform(X)\n",
        "\n",
        "        y_pred_hierarchical = []\n",
        "\n",
        "        for level in range(1, 4):\n",
        "            y_pred_level = self.models[level].predict(X_transformed)\n",
        "            y_pred_hierarchical.append(y_pred_level)\n",
        "\n",
        "        return y_pred_hierarchical[-1], y_pred_hierarchical\n",
        "\n",
        "    def evaluate(self, test_data):\n",
        "        test_data['Processed_Text'] = test_data['Text'].apply(self.preprocess_text)\n",
        "        X_test = np.array([self.text_to_vector(text) for text in test_data['Text']])\n",
        "\n",
        "        metrics = {f'Cat{level}': {'accuracy': [], 'f1': [], 'recall': [], 'precision': []} for level in range(1, 4)}\n",
        "\n",
        "        y_pred_hierarchical = []\n",
        "\n",
        "        for level in range(1, 4):\n",
        "            y_test_level = self.transform_with_unknown(self.label_encoders[level], test_data[f'Cat{level}'])\n",
        "            y_pred_level = self.models[level].predict(X_test)\n",
        "            y_pred_hierarchical.append(y_pred_level)\n",
        "\n",
        "            metrics[f'Cat{level}']['accuracy'].append(accuracy_score(y_test_level, y_pred_level))\n",
        "            metrics[f'Cat{level}']['f1'].append(f1_score(y_test_level, y_pred_level, average='macro'))\n",
        "            metrics[f'Cat{level}']['recall'].append(recall_score(y_test_level, y_pred_level, average='macro'))\n",
        "            metrics[f'Cat{level}']['precision'].append(precision_score(y_test_level, y_pred_level, average='macro'))\n",
        "\n",
        "            print(f\"--- Evaluation results for Cat{level} ---\")\n",
        "            print(f\"Accuracy: {np.mean(metrics[f'Cat{level}']['accuracy'])}\")\n",
        "            print(f\"F1 Score: {np.mean(metrics[f'Cat{level}']['f1'])}\")\n",
        "            print(f\"Recall: {np.mean(metrics[f'Cat{level}']['recall'])}\")\n",
        "            print(f\"Precision: {np.mean(metrics[f'Cat{level}']['precision'])}\")\n",
        "            print()\n",
        "\n",
        "        return metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mWW7uW4rbxeF"
      },
      "outputs": [],
      "source": [
        "texts_for_w2v = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Samokat/amazon/unlabeled_150k.csv')['Text']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60GAvEbG0R7z",
        "outputId": "fb3b6ac7-755a-4391-9472-70dabb1bf3a6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:gensim.models.word2vec:Each 'sentences' item should be a list of words (usually unicode strings). First item here is instead plain <class 'str'>.\n",
            "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<gensim.models.word2vec.Word2Vec at 0x79516750ffa0>"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "base_model = XGBClassifier(n_estimators=300, eval_metric=\"mlogloss\", use_label_encoder=False)\n",
        "classifier = LCN_HierarchicalClassifier(base_model)\n",
        "classifier.fit_word2vec(texts_for_w2v[:90000]) # Предобучаем word2vec на большом объеме данных\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7VhypUFclwd",
        "outputId": "da8ee621-3143-4e20-c3f3-9f8a7edfb2cc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [10:51:45] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Level 1 ---\n",
            "Accuracy: 0.4139139139139139\n",
            "F1 Score: 0.3661518509770749\n",
            "Recall score: 0.358710422904633\n",
            "Precision score: 0.40518879778503386\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [10:53:46] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Level 2 ---\n",
            "Accuracy: 0.17942942942942944\n",
            "F1 Score: 0.09499476856939934\n",
            "Recall score: 0.09066501783777951\n",
            "Precision score: 0.1300112335870912\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [11:04:59] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Level 3 ---\n",
            "Accuracy: 0.12374874874874875\n",
            "F1 Score: 0.05119964756174889\n",
            "Recall score: 0.047663276391831225\n",
            "Precision score: 0.07213873149849119\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<__main__.LCN_HierarchicalClassifier at 0x79516750e5c0>"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "classifier.fit(train_data, save_model_dir='/content/drive/MyDrive/Colab Notebooks/Samokat/weights')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C76_l-SyWzfF"
      },
      "source": [
        "Использование разных моделей:\n",
        "- Линейные модели не могут найти глубокие скрытые зависимости, поэтому проявляется недообучение.\n",
        "- Случайный лес склонен к переобучению, поэтому на тестовых данных показывает очень хорошее качество, но на тесте метрики плохие.\n",
        "- Бустинги показывают себя лучше всего, но они более ресурсозатратные: для обучения всего классификатора на XGBoost потребовалось около 50 минут.\n",
        "\n",
        "\n",
        "**Результат**:\n",
        "Модели на каждом уровне работают хуже LCPN + в данной структуре теряются иерархические отношения."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L5JmL0rWXvr-"
      },
      "outputs": [],
      "source": [
        "val_data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Samokat/amazon/val_10k.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dItHPDKIY7i1"
      },
      "source": [
        "# Плоский классификатор"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHgcnEM-JYLe"
      },
      "source": [
        "Идея: конкатенируем все три категории и подаем в классификатор как класс."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "0wBFh5COrNC1"
      },
      "outputs": [],
      "source": [
        "train_data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Samokat/amazon/train_40k.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "rRH4tFMcbTLV"
      },
      "outputs": [],
      "source": [
        "train_data['Flat_Class'] = train_data['Cat1'] + ' ' + train_data['Cat2'] + ' ' + train_data['Cat3']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "id": "7poAmvwnbh8R",
        "outputId": "81572a7a-f846-48b2-abcc-0d8015fb1853"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Flat_Class</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>health personal care personal care shaving hair removal</th>\n",
              "      <td>1565</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>health personal care nutrition wellness vitamins supplements</th>\n",
              "      <td>1315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>toys games games board games</th>\n",
              "      <td>924</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>beauty hair care styling tools</th>\n",
              "      <td>850</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>beauty fragrance women s</th>\n",
              "      <td>737</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>toys games novelty gag toys slime putty toys</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>toys games games handheld games</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>toys games puzzles puzzle play mats</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>toys games dolls accessories unknown</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>grocery gourmet food gourmet gifts spices gifts</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>555 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "Flat_Class\n",
              "health personal care personal care shaving hair removal         1565\n",
              "health personal care nutrition wellness vitamins supplements    1315\n",
              "toys games games board games                                     924\n",
              "beauty hair care styling tools                                   850\n",
              "beauty fragrance women s                                         737\n",
              "                                                                ... \n",
              "toys games novelty gag toys slime putty toys                       1\n",
              "toys games games handheld games                                    1\n",
              "toys games puzzles puzzle play mats                                1\n",
              "toys games dolls accessories unknown                               1\n",
              "grocery gourmet food gourmet gifts spices gifts                    1\n",
              "Name: count, Length: 555, dtype: int64"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data['Flat_Class'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "collapsed": true,
        "id": "BeBL0AmGyqqN"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from gensim.models import Word2Vec\n",
        "import numpy as np\n",
        "import pickle\n",
        "import os\n",
        "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "class FlatClassifier:\n",
        "\n",
        "    def __init__(self, base_model):\n",
        "        self.base_model = base_model\n",
        "        self.label_encoder = None\n",
        "        self.word2vec_model = None\n",
        "\n",
        "    def preprocess_text(self, text):\n",
        "        # Простая предобработка текста без использования NLTK\n",
        "        text = text.lower()\n",
        "        text = re.sub(r'\\b\\w{1,2}\\b', '', text)  # Удаляем короткие слова длиной 1-2 буквы\n",
        "        text = re.sub(r'\\d+', '', text)  # Удаляем числа\n",
        "        text = re.sub(r'\\W+', ' ', text)  # Удаляем все, кроме букв и пробелов\n",
        "        text = text.strip()\n",
        "        return text\n",
        "\n",
        "    def fit_word2vec(self, texts):\n",
        "        self.word2vec_model = Word2Vec(texts)\n",
        "        self.word2vec_model.train(texts, total_examples=len(texts), epochs=5)\n",
        "        return self.word2vec_model\n",
        "\n",
        "    def text_to_vector(self, text):\n",
        "        words = self.preprocess_text(text).split()\n",
        "        words_in_vocab = [word for word in words if word in self.word2vec_model.wv]\n",
        "        if len(words_in_vocab) == 0:\n",
        "            return np.zeros(100)\n",
        "        return np.mean([self.word2vec_model.wv[word] for word in words_in_vocab], axis=0)\n",
        "\n",
        "    def fit(self, train_data, save_model_dir=None):\n",
        "        # Объединение категорий в один класс\n",
        "        train_data['Flat_Class'] = train_data['Cat1'] + ' ' + train_data['Cat2'] + ' ' + train_data['Cat3']\n",
        "\n",
        "        # Замена редких классов на 'Other'\n",
        "        threshold = 5\n",
        "        class_counts = train_data['Flat_Class'].value_counts()\n",
        "        train_data['Flat_Class'] = train_data['Flat_Class'].apply(lambda x: x if class_counts[x] > threshold else 'Other')\n",
        "\n",
        "        # Преобразование текста в векторы\n",
        "        train_data['Processed_Text'] = train_data['Text'].apply(self.preprocess_text)\n",
        "        text = train_data['Processed_Text'].tolist()\n",
        "        X = np.array([self.text_to_vector(text) for text in train_data['Processed_Text']])\n",
        "\n",
        "        # Преобразование класса\n",
        "        self.label_encoder = LabelEncoder()\n",
        "        y = self.label_encoder.fit_transform(train_data['Flat_Class'])\n",
        "\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
        "\n",
        "        self.base_model.fit(X_train, y_train)\n",
        "\n",
        "        # Сохранение модели и энкодера,\n",
        "        if save_model_dir:\n",
        "            model_path = os.path.join(save_model_dir, '/content/drive/MyDrive/Colab Notebooks/Samokat/weights/flat_model.pkl')\n",
        "            encoder_path = os.path.join(save_model_dir, '/content/drive/MyDrive/Colab Notebooks/Samokat/weights/flat_encoder.pkl')\n",
        "            with open(model_path, 'wb') as model_file:\n",
        "                pickle.dump(self.base_model, model_file)\n",
        "            with open(encoder_path, 'wb') as encoder_file:\n",
        "                pickle.dump(self.label_encoder, encoder_file)\n",
        "\n",
        "        # Оценка модели\n",
        "        y_pred = self.base_model.predict(X_test)\n",
        "        print(f'Accuracy: {accuracy_score(y_test, y_pred)}')\n",
        "        print(f'F1 Score: {f1_score(y_test, y_pred, average=\"macro\")}')\n",
        "        print(f\"Recall score: {recall_score(y_test, y_pred, average='macro')}\")\n",
        "        print(f\"Precision score: {precision_score(y_test, y_pred, average='macro')}\")\n",
        "\n",
        "        return self\n",
        "\n",
        "    def predict(self, X, model_dir=None):\n",
        "\n",
        "        if model_dir:\n",
        "            model_path = os.path.join(model_dir, 'flat_model.pkl')\n",
        "            encoder_path = os.path.join(model_dir, 'flat_encoder.pkl')\n",
        "            with open(model_path, 'rb') as model_file:\n",
        "                self.base_model = pickle.load(model_file)\n",
        "            with open(encoder_path, 'rb') as encoder_file:\n",
        "                self.label_encoder = pickle.load(encoder_file)\n",
        "\n",
        "        X = X.apply(self.preprocess_text)\n",
        "        X_transformed = np.array([self.text_to_vector(text) for text in X])\n",
        "\n",
        "        y_pred = self.base_model.predict(X_transformed)\n",
        "        y_pred_classes = self.label_encoder.inverse_transform(y_pred)\n",
        "\n",
        "        return y_pred_classes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnCvaafhzyyf",
        "outputId": "bae05f7c-5782-4bd8-a734-cf477a5bf8c7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [14:08:04] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.26525\n",
            "F1 Score: 0.09368683256859443\n",
            "Recall score: 0.09110660603217342\n",
            "Precision score: 0.1148709416646824\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<__main__.FlatClassifier at 0x7ce4f1d2afb0>"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Инициализация и обучение модели\n",
        "base_model = XGBClassifier(n_estimators=100, eval_metric=\"mlogloss\", use_label_encoder=False)\n",
        "flat_classifier = FlatClassifier(base_model)\n",
        "\n",
        "flat_classifier.fit_word2vec(train_data['Text'].apply(flat_classifier.preprocess_text).str.split())\n",
        "\n",
        "# Обучение FlatClassifier на первых 9000 записях\n",
        "flat_classifier.fit(train_data, save_model_dir='/content/drive/MyDrive/Colab Notebooks/Samokat/weights')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glChsfjG_tib",
        "outputId": "9eff594d-2f40-4a01-b884-a09ee67d22cc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['toys games games card games',\n",
              "       'toys games action toy figures figures'], dtype=object)"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "new_data = pd.Series([\n",
        "    \"Cool Game\",\n",
        "    \"Toys is cool\"\n",
        "])\n",
        "flat_classifier.predict(new_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bb1sp_JOKJII"
      },
      "source": [
        "# ИТОГИ\n",
        "Мы обучили 3 вида классификации:\n",
        "- Local Classifier per Parent Node (LCPN) - каждый родительский узел получает один многоклассовый классификатор.\n",
        "- Local Classifier per Node (LCN) - обучение одного многоклассового классификатора для каждого уровня.\n",
        "- Flat Classifier (\"плоский\" классификатор) - обучение на конкатенированных данных.\n",
        "\n",
        "\n",
        "---\n",
        "**LCPN**.\n",
        "\n",
        "Плюсы:\n",
        "- Хорошее качество моделей относительно других структур.\n",
        "- Скорость обучения выше остальных (15 минут при обучении XGBoost).\n",
        "\n",
        "Минусы:\n",
        "- Сложность обработки редких классов.\n",
        "- Зависимость от предсказаний на предыдущих уровнях.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "**LCN**\n",
        "\n",
        "Качество моделей хуже, скорость обучения ниже (25 минут при обучении XGBoost), более высокая вычислительная сложность.\n",
        "\n",
        "\n",
        "---\n",
        "**Плоский** **классификатор**\n",
        "\n",
        "Не эффективен при работе с большим количеством классов, низкая точность.\n",
        "Временные затраты растут с увеличением количества классов, но обучение остается достаточно эффективным, поскольку весь процесс сводится к одному вызову алгоритма обучения."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rmM9lZ0aKaCL"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
